{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, nltk\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('nips12raw_str602', <http.client.HTTPMessage at 0x7f86860fb490>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "url = 'https://cs.nyu.edu/~roweis/data/nips12raw_str602.tgz'\n",
    "filename = 'nips12raw_str602'\n",
    "urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xzf nips12raw_str602"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['orig', 'nips06', 'nips08', 'nips00', 'nips04', 'idx', 'nips02', 'README_yann', 'nips10', 'nips11', 'nips01', 'nips03', 'nips09', 'nips12', 'nips07', 'MATLAB_NOTES', 'nips05', 'RAW_DATA_NOTES']\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = 'nipstxt/'\n",
    "print(os.listdir(DATA_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and View Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1740"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders = ['nips{0:02}'.format(i) for i in range(0, 13)]\n",
    "# Read all texts into a list\n",
    "papers = []\n",
    "for folder in folders:\n",
    "    file_names = os.listdir(DATA_PATH + folder)\n",
    "    for file_name in file_names:\n",
    "        with open(DATA_PATH + folder + '/' + file_name, encoding='utf-8', errors='ignore', mode='r+') as f:#seperate 'em with /\n",
    "            data = f.read()\n",
    "        papers.append(data)\n",
    "len(papers)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " However, it looks like the OCR hasn’t worked perfectly and we have\n",
    "some missing characters here and there. This is expected, but also makes this task more\n",
    "challenging!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "804 \n",
      "INTRODUCTION TO A SYSTEM FOR IMPLEMENTING NEURAL NET \n",
      "CONNECTIONS ON SIMD ARCHITECTURES \n",
      "Sherryl Tomboulian \n",
      "Institute for Computer Applications in Science and Engineering \n",
      "NASA Langley Research Center, Hampton VA 23665 \n",
      "ABSTRACT \n",
      "Neural networks have attracted much interest recently, and using parallel \n",
      "architectures to simulate neural networks is a natural and necessary applica- \n",
      "tion. The SIMD model of parallel computation is chosen, because systems of \n",
      "this type can be built with large numbers of processing elements. However, \n",
      "such systems are not naturally suited to generalized communication. A method \n",
      "is proposed that allows an implementation of neural network connections on \n",
      "massively parallel SIMD architectures. The key to this system is an algorithm \n",
      "that allows the formation of arbitrary connections between the 'neurons '. A \n",
      "feature is the ability to add new connections quickly. It also has error recov- \n",
      "ery ability and is robust over a variety of network topologies. Si\n"
     ]
    }
   ],
   "source": [
    "print(papers[0][:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Text Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1740\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "wtk = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "wnl = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "\n",
    "def normalize_corpus(papers):\n",
    "    norm_papers = []\n",
    "    for paper in papers:\n",
    "        paper = paper.lower()\n",
    "        paper_tokens = [token.strip() for token in wtk.tokenize(paper)]# word tokenization\n",
    "        paper_tokens = [wnl.lemmatize(token) for token in paper_tokens if not token.isnumeric()]\n",
    "        paper_tokens = [token for token in paper_tokens if len(token) > 1]\n",
    "        paper_tokens = [token for token in paper_tokens if token not in stop_words]\n",
    "        paper_tokens = list(filter(None, paper_tokens))\n",
    "        if paper_tokens:\n",
    "            norm_papers.append(paper_tokens)\n",
    "            \n",
    "    return norm_papers\n",
    "\n",
    "norm_papers = normalize_corpus(papers)\n",
    "print(len(norm_papers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['introduction', 'system', 'implementing', 'neural', 'net', 'connection', 'simd', 'architecture', 'sherryl', 'tomboulian', 'institute', 'computer', 'application', 'science', 'engineering', 'nasa', 'langley', 'research', 'center', 'hampton', 'va', 'abstract', 'neural', 'network', 'attracted', 'much', 'interest', 'recently', 'using', 'parallel', 'architecture', 'simulate', 'neural', 'network', 'natural', 'necessary', 'applica', 'tion', 'simd', 'model', 'parallel', 'computation', 'chosen', 'system', 'type', 'built', 'large', 'number', 'processing', 'element']\n"
     ]
    }
   ],
   "source": [
    "# Viewing a processed paper\n",
    "print(norm_papers[0][:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Representation with Feature Engineering¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we present out text data in thr form of a Bag of Words model with uni-gram and bi-gram, similar to our analyses in the previous section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1740, 14408)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv=CountVectorizer(min_df=20, max_df=0.6,ngram_range=(1, 2),token_pattern=None,tokenizer=lambda doc:doc,preprocessor=lambda doc:doc)\n",
    "cv_feature = cv.fit_transform(norm_papers)\n",
    "cv_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Vocabulary Size: 14408\n"
     ]
    }
   ],
   "source": [
    "# validating vocaublary size\n",
    "vocabulary = np.array(cv.get_feature_names())\n",
    "print('Total Vocabulary Size:', len(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Semantic Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "TOTAL_TOPICS = 20\n",
    "lsi_model = TruncatedSVD(n_components=TOTAL_TOPICS, n_iter=500, random_state=42)\n",
    "document_topics = lsi_model.fit_transform(cv_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 14408)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_terms = lsi_model.components_\n",
    "topic_terms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1:\n",
      "==================================================\n",
      "Direction 1: [('state', 0.221), ('neuron', 0.169), ('image', 0.138), ('cell', 0.13), ('layer', 0.13), ('feature', 0.127), ('probability', 0.121), ('hidden', 0.114), ('distribution', 0.105), ('rate', 0.098), ('signal', 0.095), ('task', 0.093), ('class', 0.092), ('noise', 0.09), ('net', 0.089), ('recognition', 0.089), ('representation', 0.088), ('field', 0.082), ('rule', 0.082), ('step', 0.08)]\n",
      "--------------------------------------------------\n",
      "Direction 2: []\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #2:\n",
      "==================================================\n",
      "Direction 1: [('cell', 0.417), ('neuron', 0.39), ('response', 0.175), ('stimulus', 0.155), ('visual', 0.131), ('spike', 0.13), ('firing', 0.117), ('synaptic', 0.11), ('activity', 0.104), ('cortex', 0.097), ('field', 0.085), ('frequency', 0.085), ('direction', 0.082), ('circuit', 0.082), ('motion', 0.082)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('state', -0.289), ('probability', -0.109), ('hidden', -0.098), ('class', -0.091), ('policy', -0.081)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #3:\n",
      "==================================================\n",
      "Direction 1: [('state', 0.574), ('neuron', 0.212), ('action', 0.187), ('policy', 0.149), ('control', 0.12), ('dynamic', 0.1), ('cell', 0.083), ('reinforcement', 0.081), ('optimal', 0.075), ('reinforcement learning', 0.068)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('image', -0.364), ('feature', -0.223), ('object', -0.144), ('recognition', -0.143), ('classifier', -0.111), ('class', -0.106), ('layer', -0.092), ('classification', -0.085), ('face', -0.073), ('test', -0.069)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #4:\n",
      "==================================================\n",
      "Direction 1: [('image', 0.425), ('state', 0.326), ('object', 0.215), ('feature', 0.159), ('action', 0.147), ('visual', 0.143), ('control', 0.126), ('task', 0.111), ('policy', 0.103), ('recognition', 0.103), ('face', 0.092), ('representation', 0.086), ('motion', 0.086)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('neuron', -0.216), ('distribution', -0.166), ('class', -0.112), ('bound', -0.109), ('probability', -0.108), ('spike', -0.104), ('variable', -0.087)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #5:\n",
      "==================================================\n",
      "Direction 1: [('layer', 0.261), ('net', 0.225), ('hidden', 0.222), ('neuron', 0.216), ('word', 0.206), ('recognition', 0.17), ('speech', 0.152), ('hidden unit', 0.11), ('architecture', 0.102), ('task', 0.094), ('activation', 0.092), ('memory', 0.091)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('cell', -0.227), ('distribution', -0.222), ('image', -0.175), ('gaussian', -0.125), ('variable', -0.112), ('density', -0.108), ('probability', -0.099), ('approximation', -0.091)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #6:\n",
      "==================================================\n",
      "Direction 1: [('cell', 0.548), ('layer', 0.139), ('word', 0.124), ('hidden', 0.111), ('classifier', 0.097), ('direction', 0.09), ('head', 0.078), ('rule', 0.073), ('rat', 0.073), ('speech', 0.071)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('neuron', -0.416), ('image', -0.336), ('circuit', -0.126), ('noise', -0.124), ('chip', -0.121), ('analog', -0.099), ('object', -0.09), ('spike', -0.075), ('signal', -0.071), ('voltage', -0.069)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #7:\n",
      "==================================================\n",
      "Direction 1: [('word', 0.294), ('recognition', 0.252), ('speech', 0.213), ('probability', 0.194), ('classifier', 0.181), ('spike', 0.179), ('state', 0.162), ('class', 0.14), ('neuron', 0.136), ('rate', 0.123), ('hmm', 0.119), ('feature', 0.112), ('classification', 0.097), ('speaker', 0.093), ('cell', 0.091)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('hidden', -0.207), ('layer', -0.179), ('hidden unit', -0.16), ('net', -0.136), ('field', -0.117)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #8:\n",
      "==================================================\n",
      "Direction 1: [('signal', 0.278), ('noise', 0.208), ('speech', 0.197), ('word', 0.165), ('hidden', 0.123), ('control', 0.117), ('motion', 0.116), ('filter', 0.108), ('frequency', 0.102)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('classifier', -0.225), ('node', -0.21), ('class', -0.197), ('feature', -0.186), ('neuron', -0.177), ('tree', -0.162), ('cell', -0.133), ('image', -0.119), ('rule', -0.115), ('object', -0.106), ('decision', -0.103)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #9:\n",
      "==================================================\n",
      "Direction 1: [('circuit', 0.244), ('control', 0.242), ('classifier', 0.229), ('chip', 0.167), ('node', 0.137), ('current', 0.132), ('analog', 0.13), ('voltage', 0.129), ('signal', 0.118), ('controller', 0.088)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('hidden', -0.27), ('neuron', -0.247), ('state', -0.175), ('distribution', -0.158), ('hidden unit', -0.143), ('layer', -0.125), ('object', -0.115), ('probability', -0.108), ('image', -0.1), ('representation', -0.098)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #10:\n",
      "==================================================\n",
      "Direction 1: [('circuit', 0.245), ('cell', 0.225), ('node', 0.211), ('state', 0.183), ('image', 0.166), ('chip', 0.163), ('analog', 0.147), ('layer', 0.144), ('net', 0.12), ('voltage', 0.115)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('task', -0.201), ('rule', -0.193), ('spike', -0.166), ('feature', -0.165), ('control', -0.157), ('neuron', -0.144), ('rate', -0.134), ('stimulus', -0.116), ('classifier', -0.116), ('action', -0.112)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #11:\n",
      "==================================================\n",
      "Direction 1: [('image', 0.315), ('cell', 0.225), ('hidden', 0.205), ('spike', 0.192), ('noise', 0.163), ('rate', 0.141), ('hidden unit', 0.141), ('rule', 0.138), ('signal', 0.119), ('net', 0.111)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('field', -0.203), ('object', -0.2), ('word', -0.184), ('node', -0.161), ('motion', -0.136), ('visual', -0.134), ('neuron', -0.128), ('structure', -0.121), ('tree', -0.119), ('map', -0.107)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #12:\n",
      "==================================================\n",
      "Direction 1: [('rule', 0.581), ('representation', 0.156), ('word', 0.146), ('memory', 0.137), ('structure', 0.125), ('matrix', 0.108), ('cell', 0.086)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('classifier', -0.293), ('layer', -0.17), ('hidden', -0.16), ('motion', -0.129), ('neuron', -0.129), ('field', -0.12), ('class', -0.109), ('visual', -0.101), ('net', -0.092), ('state', -0.085), ('region', -0.084), ('hidden unit', -0.076), ('stimulus', -0.076)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #13:\n",
      "==================================================\n",
      "Direction 1: [('node', 0.396), ('tree', 0.262), ('spike', 0.226), ('stimulus', 0.208), ('signal', 0.169), ('representation', 0.147), ('motion', 0.142), ('response', 0.138), ('frequency', 0.109), ('visual', 0.1), ('rate', 0.097)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('cell', -0.231), ('feature', -0.157), ('neuron', -0.147), ('control', -0.13), ('matrix', -0.119), ('word', -0.114), ('recognition', -0.113), ('distance', -0.104), ('equation', -0.098)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #14:\n",
      "==================================================\n",
      "Direction 1: [('feature', 0.506), ('noise', 0.196), ('map', 0.171), ('signal', 0.133), ('classifier', 0.129), ('state', 0.124), ('memory', 0.122), ('orientation', 0.109), ('component', 0.103)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('image', -0.254), ('control', -0.187), ('word', -0.162), ('recognition', -0.132), ('neuron', -0.131), ('object', -0.113), ('rate', -0.105), ('character', -0.099), ('probability', -0.096), ('bound', -0.089), ('rule', -0.086)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #15:\n",
      "==================================================\n",
      "Direction 1: [('rule', 0.365), ('classifier', 0.365), ('mixture', 0.171), ('node', 0.156), ('gaussian', 0.148), ('layer', 0.128), ('neuron', 0.114), ('field', 0.109), ('control', 0.108), ('image', 0.104), ('component', 0.098)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('bound', -0.189), ('word', -0.156), ('feature', -0.136), ('threshold', -0.135), ('object', -0.125), ('representation', -0.118), ('size', -0.117), ('task', -0.098), ('theorem', -0.097)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #16:\n",
      "==================================================\n",
      "Direction 1: [('object', 0.291), ('control', 0.206), ('mixture', 0.178), ('feature', 0.158), ('task', 0.132), ('cell', 0.13), ('variable', 0.125), ('expert', 0.117), ('current', 0.117), ('circuit', 0.115), ('tree', 0.101), ('distribution', 0.098)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('word', -0.21), ('field', -0.172), ('rule', -0.138), ('rate', -0.121), ('motion', -0.116), ('character', -0.108), ('orientation', -0.107), ('image', -0.104)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #17:\n",
      "==================================================\n",
      "Direction 1: [('rule', 0.372), ('motion', 0.325), ('circuit', 0.193), ('direction', 0.175), ('neuron', 0.153), ('chip', 0.127), ('task', 0.123), ('visual', 0.113), ('velocity', 0.092), ('action', 0.091)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('memory', -0.231), ('node', -0.215), ('control', -0.182), ('dynamic', -0.148), ('spike', -0.128), ('rate', -0.116), ('matrix', -0.108), ('noise', -0.103), ('fig', -0.097), ('cell', -0.093)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #18:\n",
      "==================================================\n",
      "Direction 1: [('object', 0.419), ('signal', 0.26), ('layer', 0.258), ('rule', 0.209), ('feature', 0.164), ('view', 0.162), ('net', 0.113), ('noise', 0.112), ('bound', 0.105), ('speech', 0.1)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('memory', -0.18), ('task', -0.161), ('representation', -0.14), ('hidden', -0.137), ('image', -0.135), ('hidden unit', -0.121), ('tree', -0.117), ('structure', -0.094), ('test', -0.093), ('word', -0.092)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #19:\n",
      "==================================================\n",
      "Direction 1: [('class', 0.287), ('memory', 0.275), ('classifier', 0.144), ('response', 0.139), ('sequence', 0.112), ('component', 0.11), ('stimulus', 0.101), ('region', 0.092), ('bound', 0.088)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('node', -0.292), ('feature', -0.244), ('field', -0.202), ('rate', -0.152), ('word', -0.146), ('spike', -0.139), ('map', -0.132), ('character', -0.127), ('policy', -0.108), ('tree', -0.092), ('noise', -0.088)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #20:\n",
      "==================================================\n",
      "Direction 1: [('map', 0.222), ('control', 0.2), ('region', 0.181), ('ii', 0.145), ('feature', 0.132), ('image', 0.122), ('bound', 0.11), ('orientation', 0.109), ('rule', 0.109), ('threshold', 0.094), ('class', 0.092)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('object', -0.31), ('motion', -0.252), ('direction', -0.229), ('memory', -0.223), ('classifier', -0.193), ('view', -0.136), ('matrix', -0.13), ('rate', -0.121), ('distance', -0.11)]\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_terms = 20\n",
    "topic_key_term_idxs = np.argsort(-np.absolute(topic_terms), axis=1)[:, :top_terms]\n",
    "topic_keyterm_weights = np.array([topic_terms[row, columns] for row, columns in list(zip(np.arange(TOTAL_TOPICS), topic_key_term_idxs))])\n",
    "topic_keyterms = vocabulary[topic_key_term_idxs]\n",
    "topic_keyterms_weights = list(zip(topic_keyterms, topic_keyterm_weights))\n",
    "for n in range(TOTAL_TOPICS):\n",
    "    print('Topic #'+str(n+1)+':')\n",
    "    print('='*50)\n",
    "    d1 = []\n",
    "    d2 = []\n",
    "    terms, weights = topic_keyterms_weights[n]\n",
    "    term_weights = sorted([(t, w) for t, w in zip(terms, weights)], key=lambda row: -abs(row[1]))\n",
    "    for term, wt in term_weights:\n",
    "        if wt >= 0:\n",
    "            d1.append((term, round(wt, 3)))\n",
    "        else:\n",
    "            d2.append((term, round(wt, 3)))\n",
    "\n",
    "    print('Direction 1:', d1)\n",
    "    print('-'*50)\n",
    "    print('Direction 2:', d2)\n",
    "    print('-'*50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1730</th>\n",
       "      <th>1731</th>\n",
       "      <th>1732</th>\n",
       "      <th>1733</th>\n",
       "      <th>1734</th>\n",
       "      <th>1735</th>\n",
       "      <th>1736</th>\n",
       "      <th>1737</th>\n",
       "      <th>1738</th>\n",
       "      <th>1739</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T1</th>\n",
       "      <td>42.714</td>\n",
       "      <td>44.822</td>\n",
       "      <td>46.477</td>\n",
       "      <td>20.943</td>\n",
       "      <td>17.548</td>\n",
       "      <td>32.834</td>\n",
       "      <td>34.128</td>\n",
       "      <td>23.130</td>\n",
       "      <td>25.540</td>\n",
       "      <td>30.974</td>\n",
       "      <td>...</td>\n",
       "      <td>38.755</td>\n",
       "      <td>31.059</td>\n",
       "      <td>36.184</td>\n",
       "      <td>36.118</td>\n",
       "      <td>43.202</td>\n",
       "      <td>22.319</td>\n",
       "      <td>19.539</td>\n",
       "      <td>29.186</td>\n",
       "      <td>60.692</td>\n",
       "      <td>51.970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T2</th>\n",
       "      <td>17.770</td>\n",
       "      <td>6.649</td>\n",
       "      <td>-8.457</td>\n",
       "      <td>-5.107</td>\n",
       "      <td>-3.635</td>\n",
       "      <td>5.514</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-4.835</td>\n",
       "      <td>8.066</td>\n",
       "      <td>1.370</td>\n",
       "      <td>...</td>\n",
       "      <td>27.500</td>\n",
       "      <td>-8.146</td>\n",
       "      <td>-21.410</td>\n",
       "      <td>-12.730</td>\n",
       "      <td>-8.751</td>\n",
       "      <td>-7.387</td>\n",
       "      <td>-11.271</td>\n",
       "      <td>-9.614</td>\n",
       "      <td>-25.865</td>\n",
       "      <td>-47.552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T3</th>\n",
       "      <td>8.193</td>\n",
       "      <td>18.312</td>\n",
       "      <td>12.215</td>\n",
       "      <td>-4.495</td>\n",
       "      <td>-2.611</td>\n",
       "      <td>-5.521</td>\n",
       "      <td>18.723</td>\n",
       "      <td>-7.784</td>\n",
       "      <td>0.556</td>\n",
       "      <td>-15.393</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.196</td>\n",
       "      <td>-3.255</td>\n",
       "      <td>34.469</td>\n",
       "      <td>-7.267</td>\n",
       "      <td>-39.015</td>\n",
       "      <td>-3.767</td>\n",
       "      <td>-4.953</td>\n",
       "      <td>-18.183</td>\n",
       "      <td>32.383</td>\n",
       "      <td>74.061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T4</th>\n",
       "      <td>-9.513</td>\n",
       "      <td>-13.303</td>\n",
       "      <td>-1.709</td>\n",
       "      <td>-9.058</td>\n",
       "      <td>-4.445</td>\n",
       "      <td>8.966</td>\n",
       "      <td>1.518</td>\n",
       "      <td>-5.905</td>\n",
       "      <td>-1.812</td>\n",
       "      <td>12.518</td>\n",
       "      <td>...</td>\n",
       "      <td>26.063</td>\n",
       "      <td>-7.138</td>\n",
       "      <td>16.593</td>\n",
       "      <td>-12.591</td>\n",
       "      <td>27.755</td>\n",
       "      <td>-6.691</td>\n",
       "      <td>-8.819</td>\n",
       "      <td>-1.926</td>\n",
       "      <td>21.709</td>\n",
       "      <td>38.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T5</th>\n",
       "      <td>22.028</td>\n",
       "      <td>8.986</td>\n",
       "      <td>-10.586</td>\n",
       "      <td>7.615</td>\n",
       "      <td>2.215</td>\n",
       "      <td>-10.962</td>\n",
       "      <td>16.546</td>\n",
       "      <td>3.375</td>\n",
       "      <td>8.839</td>\n",
       "      <td>-12.691</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.270</td>\n",
       "      <td>1.579</td>\n",
       "      <td>-1.060</td>\n",
       "      <td>-8.808</td>\n",
       "      <td>-18.840</td>\n",
       "      <td>-7.650</td>\n",
       "      <td>-7.030</td>\n",
       "      <td>-7.298</td>\n",
       "      <td>-3.606</td>\n",
       "      <td>-9.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T6</th>\n",
       "      <td>-16.731</td>\n",
       "      <td>-20.833</td>\n",
       "      <td>-8.040</td>\n",
       "      <td>3.771</td>\n",
       "      <td>2.400</td>\n",
       "      <td>-14.726</td>\n",
       "      <td>-11.580</td>\n",
       "      <td>0.267</td>\n",
       "      <td>-4.417</td>\n",
       "      <td>-13.965</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.659</td>\n",
       "      <td>4.988</td>\n",
       "      <td>6.211</td>\n",
       "      <td>4.504</td>\n",
       "      <td>-22.516</td>\n",
       "      <td>-0.643</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.723</td>\n",
       "      <td>12.865</td>\n",
       "      <td>1.262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T7</th>\n",
       "      <td>-13.660</td>\n",
       "      <td>2.279</td>\n",
       "      <td>-12.092</td>\n",
       "      <td>-8.912</td>\n",
       "      <td>-9.673</td>\n",
       "      <td>-9.546</td>\n",
       "      <td>-5.158</td>\n",
       "      <td>-5.809</td>\n",
       "      <td>4.530</td>\n",
       "      <td>-5.678</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.561</td>\n",
       "      <td>-3.196</td>\n",
       "      <td>2.442</td>\n",
       "      <td>-1.409</td>\n",
       "      <td>12.851</td>\n",
       "      <td>-2.714</td>\n",
       "      <td>1.234</td>\n",
       "      <td>12.992</td>\n",
       "      <td>16.353</td>\n",
       "      <td>14.963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T8</th>\n",
       "      <td>-18.427</td>\n",
       "      <td>-9.052</td>\n",
       "      <td>4.081</td>\n",
       "      <td>-3.682</td>\n",
       "      <td>0.327</td>\n",
       "      <td>3.658</td>\n",
       "      <td>-13.321</td>\n",
       "      <td>4.941</td>\n",
       "      <td>12.250</td>\n",
       "      <td>3.065</td>\n",
       "      <td>...</td>\n",
       "      <td>13.246</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>0.823</td>\n",
       "      <td>-5.276</td>\n",
       "      <td>-19.979</td>\n",
       "      <td>-4.121</td>\n",
       "      <td>1.603</td>\n",
       "      <td>-7.423</td>\n",
       "      <td>12.649</td>\n",
       "      <td>-16.091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T9</th>\n",
       "      <td>1.199</td>\n",
       "      <td>-5.040</td>\n",
       "      <td>6.762</td>\n",
       "      <td>-1.345</td>\n",
       "      <td>1.153</td>\n",
       "      <td>17.199</td>\n",
       "      <td>-5.996</td>\n",
       "      <td>-1.381</td>\n",
       "      <td>12.249</td>\n",
       "      <td>2.538</td>\n",
       "      <td>...</td>\n",
       "      <td>33.609</td>\n",
       "      <td>4.350</td>\n",
       "      <td>-6.278</td>\n",
       "      <td>2.288</td>\n",
       "      <td>0.588</td>\n",
       "      <td>7.977</td>\n",
       "      <td>4.682</td>\n",
       "      <td>-4.812</td>\n",
       "      <td>-16.777</td>\n",
       "      <td>-20.378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T10</th>\n",
       "      <td>5.723</td>\n",
       "      <td>7.673</td>\n",
       "      <td>2.857</td>\n",
       "      <td>6.169</td>\n",
       "      <td>-4.514</td>\n",
       "      <td>19.623</td>\n",
       "      <td>9.756</td>\n",
       "      <td>-1.090</td>\n",
       "      <td>1.130</td>\n",
       "      <td>4.474</td>\n",
       "      <td>...</td>\n",
       "      <td>12.802</td>\n",
       "      <td>-8.582</td>\n",
       "      <td>3.458</td>\n",
       "      <td>10.627</td>\n",
       "      <td>4.010</td>\n",
       "      <td>-5.835</td>\n",
       "      <td>-6.096</td>\n",
       "      <td>-11.090</td>\n",
       "      <td>18.002</td>\n",
       "      <td>17.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T11</th>\n",
       "      <td>-18.611</td>\n",
       "      <td>-13.316</td>\n",
       "      <td>-7.474</td>\n",
       "      <td>-1.671</td>\n",
       "      <td>5.203</td>\n",
       "      <td>-3.081</td>\n",
       "      <td>-4.188</td>\n",
       "      <td>7.682</td>\n",
       "      <td>0.592</td>\n",
       "      <td>9.864</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.806</td>\n",
       "      <td>6.592</td>\n",
       "      <td>6.075</td>\n",
       "      <td>-9.303</td>\n",
       "      <td>21.953</td>\n",
       "      <td>-1.427</td>\n",
       "      <td>0.346</td>\n",
       "      <td>-5.765</td>\n",
       "      <td>-8.298</td>\n",
       "      <td>3.359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T12</th>\n",
       "      <td>6.124</td>\n",
       "      <td>1.045</td>\n",
       "      <td>6.483</td>\n",
       "      <td>-2.373</td>\n",
       "      <td>4.828</td>\n",
       "      <td>-1.519</td>\n",
       "      <td>5.295</td>\n",
       "      <td>-2.832</td>\n",
       "      <td>4.728</td>\n",
       "      <td>0.930</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.171</td>\n",
       "      <td>-3.156</td>\n",
       "      <td>-7.917</td>\n",
       "      <td>3.059</td>\n",
       "      <td>-1.860</td>\n",
       "      <td>3.283</td>\n",
       "      <td>-1.176</td>\n",
       "      <td>4.507</td>\n",
       "      <td>1.787</td>\n",
       "      <td>-8.688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T13</th>\n",
       "      <td>-10.872</td>\n",
       "      <td>-0.721</td>\n",
       "      <td>-11.260</td>\n",
       "      <td>6.468</td>\n",
       "      <td>-2.997</td>\n",
       "      <td>4.064</td>\n",
       "      <td>-8.438</td>\n",
       "      <td>-2.888</td>\n",
       "      <td>4.502</td>\n",
       "      <td>-0.960</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.764</td>\n",
       "      <td>3.114</td>\n",
       "      <td>3.068</td>\n",
       "      <td>11.719</td>\n",
       "      <td>-2.733</td>\n",
       "      <td>-8.155</td>\n",
       "      <td>-9.317</td>\n",
       "      <td>-12.753</td>\n",
       "      <td>-6.422</td>\n",
       "      <td>11.239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T14</th>\n",
       "      <td>1.479</td>\n",
       "      <td>1.525</td>\n",
       "      <td>5.605</td>\n",
       "      <td>-3.909</td>\n",
       "      <td>-1.767</td>\n",
       "      <td>-3.491</td>\n",
       "      <td>11.908</td>\n",
       "      <td>6.394</td>\n",
       "      <td>3.957</td>\n",
       "      <td>-5.271</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>-0.559</td>\n",
       "      <td>-0.251</td>\n",
       "      <td>-6.520</td>\n",
       "      <td>-20.452</td>\n",
       "      <td>0.182</td>\n",
       "      <td>-1.983</td>\n",
       "      <td>24.113</td>\n",
       "      <td>13.087</td>\n",
       "      <td>13.895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T15</th>\n",
       "      <td>2.937</td>\n",
       "      <td>4.044</td>\n",
       "      <td>-2.378</td>\n",
       "      <td>4.341</td>\n",
       "      <td>3.186</td>\n",
       "      <td>4.107</td>\n",
       "      <td>3.046</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-2.603</td>\n",
       "      <td>2.809</td>\n",
       "      <td>...</td>\n",
       "      <td>5.374</td>\n",
       "      <td>-9.748</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-3.357</td>\n",
       "      <td>4.143</td>\n",
       "      <td>-8.037</td>\n",
       "      <td>-4.177</td>\n",
       "      <td>-11.103</td>\n",
       "      <td>4.987</td>\n",
       "      <td>4.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T16</th>\n",
       "      <td>-0.871</td>\n",
       "      <td>-9.992</td>\n",
       "      <td>-12.826</td>\n",
       "      <td>2.476</td>\n",
       "      <td>-6.084</td>\n",
       "      <td>-8.164</td>\n",
       "      <td>-10.658</td>\n",
       "      <td>-1.781</td>\n",
       "      <td>3.684</td>\n",
       "      <td>-10.141</td>\n",
       "      <td>...</td>\n",
       "      <td>11.600</td>\n",
       "      <td>1.294</td>\n",
       "      <td>4.907</td>\n",
       "      <td>8.438</td>\n",
       "      <td>-8.383</td>\n",
       "      <td>-6.757</td>\n",
       "      <td>-0.973</td>\n",
       "      <td>10.221</td>\n",
       "      <td>-0.385</td>\n",
       "      <td>-4.314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T17</th>\n",
       "      <td>3.353</td>\n",
       "      <td>-4.147</td>\n",
       "      <td>-4.401</td>\n",
       "      <td>-2.244</td>\n",
       "      <td>5.328</td>\n",
       "      <td>10.674</td>\n",
       "      <td>-20.114</td>\n",
       "      <td>-1.062</td>\n",
       "      <td>-2.009</td>\n",
       "      <td>-4.649</td>\n",
       "      <td>...</td>\n",
       "      <td>9.764</td>\n",
       "      <td>-2.794</td>\n",
       "      <td>4.974</td>\n",
       "      <td>1.406</td>\n",
       "      <td>-3.390</td>\n",
       "      <td>4.302</td>\n",
       "      <td>2.208</td>\n",
       "      <td>6.244</td>\n",
       "      <td>-2.361</td>\n",
       "      <td>5.723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T18</th>\n",
       "      <td>-14.883</td>\n",
       "      <td>-2.007</td>\n",
       "      <td>0.707</td>\n",
       "      <td>3.353</td>\n",
       "      <td>3.306</td>\n",
       "      <td>1.841</td>\n",
       "      <td>-7.151</td>\n",
       "      <td>3.912</td>\n",
       "      <td>3.338</td>\n",
       "      <td>-0.579</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.183</td>\n",
       "      <td>-4.020</td>\n",
       "      <td>-3.091</td>\n",
       "      <td>-9.126</td>\n",
       "      <td>-11.791</td>\n",
       "      <td>2.532</td>\n",
       "      <td>-1.150</td>\n",
       "      <td>3.147</td>\n",
       "      <td>3.002</td>\n",
       "      <td>1.753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T19</th>\n",
       "      <td>-10.669</td>\n",
       "      <td>-1.725</td>\n",
       "      <td>-4.386</td>\n",
       "      <td>-4.706</td>\n",
       "      <td>1.120</td>\n",
       "      <td>-8.771</td>\n",
       "      <td>23.687</td>\n",
       "      <td>-6.087</td>\n",
       "      <td>3.631</td>\n",
       "      <td>-1.905</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.098</td>\n",
       "      <td>-4.024</td>\n",
       "      <td>-1.812</td>\n",
       "      <td>-10.781</td>\n",
       "      <td>15.993</td>\n",
       "      <td>-1.514</td>\n",
       "      <td>0.240</td>\n",
       "      <td>-12.922</td>\n",
       "      <td>2.043</td>\n",
       "      <td>0.906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T20</th>\n",
       "      <td>-10.036</td>\n",
       "      <td>-11.724</td>\n",
       "      <td>-6.764</td>\n",
       "      <td>-0.122</td>\n",
       "      <td>0.289</td>\n",
       "      <td>-4.483</td>\n",
       "      <td>-18.266</td>\n",
       "      <td>-0.931</td>\n",
       "      <td>3.806</td>\n",
       "      <td>0.907</td>\n",
       "      <td>...</td>\n",
       "      <td>14.473</td>\n",
       "      <td>-4.022</td>\n",
       "      <td>2.814</td>\n",
       "      <td>-1.032</td>\n",
       "      <td>17.903</td>\n",
       "      <td>-4.415</td>\n",
       "      <td>-2.936</td>\n",
       "      <td>5.720</td>\n",
       "      <td>6.197</td>\n",
       "      <td>-0.798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 1740 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8     \\\n",
       "T1   42.714  44.822  46.477  20.943  17.548  32.834  34.128  23.130  25.540   \n",
       "T2   17.770   6.649  -8.457  -5.107  -3.635   5.514  -0.007  -4.835   8.066   \n",
       "T3    8.193  18.312  12.215  -4.495  -2.611  -5.521  18.723  -7.784   0.556   \n",
       "T4   -9.513 -13.303  -1.709  -9.058  -4.445   8.966   1.518  -5.905  -1.812   \n",
       "T5   22.028   8.986 -10.586   7.615   2.215 -10.962  16.546   3.375   8.839   \n",
       "T6  -16.731 -20.833  -8.040   3.771   2.400 -14.726 -11.580   0.267  -4.417   \n",
       "T7  -13.660   2.279 -12.092  -8.912  -9.673  -9.546  -5.158  -5.809   4.530   \n",
       "T8  -18.427  -9.052   4.081  -3.682   0.327   3.658 -13.321   4.941  12.250   \n",
       "T9    1.199  -5.040   6.762  -1.345   1.153  17.199  -5.996  -1.381  12.249   \n",
       "T10   5.723   7.673   2.857   6.169  -4.514  19.623   9.756  -1.090   1.130   \n",
       "T11 -18.611 -13.316  -7.474  -1.671   5.203  -3.081  -4.188   7.682   0.592   \n",
       "T12   6.124   1.045   6.483  -2.373   4.828  -1.519   5.295  -2.832   4.728   \n",
       "T13 -10.872  -0.721 -11.260   6.468  -2.997   4.064  -8.438  -2.888   4.502   \n",
       "T14   1.479   1.525   5.605  -3.909  -1.767  -3.491  11.908   6.394   3.957   \n",
       "T15   2.937   4.044  -2.378   4.341   3.186   4.107   3.046  -0.028  -2.603   \n",
       "T16  -0.871  -9.992 -12.826   2.476  -6.084  -8.164 -10.658  -1.781   3.684   \n",
       "T17   3.353  -4.147  -4.401  -2.244   5.328  10.674 -20.114  -1.062  -2.009   \n",
       "T18 -14.883  -2.007   0.707   3.353   3.306   1.841  -7.151   3.912   3.338   \n",
       "T19 -10.669  -1.725  -4.386  -4.706   1.120  -8.771  23.687  -6.087   3.631   \n",
       "T20 -10.036 -11.724  -6.764  -0.122   0.289  -4.483 -18.266  -0.931   3.806   \n",
       "\n",
       "       9     ...    1730    1731    1732    1733    1734    1735    1736  \\\n",
       "T1   30.974  ...  38.755  31.059  36.184  36.118  43.202  22.319  19.539   \n",
       "T2    1.370  ...  27.500  -8.146 -21.410 -12.730  -8.751  -7.387 -11.271   \n",
       "T3  -15.393  ...  -2.196  -3.255  34.469  -7.267 -39.015  -3.767  -4.953   \n",
       "T4   12.518  ...  26.063  -7.138  16.593 -12.591  27.755  -6.691  -8.819   \n",
       "T5  -12.691  ...  -6.270   1.579  -1.060  -8.808 -18.840  -7.650  -7.030   \n",
       "T6  -13.965  ...  -2.659   4.988   6.211   4.504 -22.516  -0.643   0.352   \n",
       "T7   -5.678  ... -12.561  -3.196   2.442  -1.409  12.851  -2.714   1.234   \n",
       "T8    3.065  ...  13.246  -0.025   0.823  -5.276 -19.979  -4.121   1.603   \n",
       "T9    2.538  ...  33.609   4.350  -6.278   2.288   0.588   7.977   4.682   \n",
       "T10   4.474  ...  12.802  -8.582   3.458  10.627   4.010  -5.835  -6.096   \n",
       "T11   9.864  ... -12.806   6.592   6.075  -9.303  21.953  -1.427   0.346   \n",
       "T12   0.930  ...  -7.171  -3.156  -7.917   3.059  -1.860   3.283  -1.176   \n",
       "T13  -0.960  ...  -5.764   3.114   3.068  11.719  -2.733  -8.155  -9.317   \n",
       "T14  -5.271  ...  -0.064  -0.559  -0.251  -6.520 -20.452   0.182  -1.983   \n",
       "T15   2.809  ...   5.374  -9.748   0.054  -3.357   4.143  -8.037  -4.177   \n",
       "T16 -10.141  ...  11.600   1.294   4.907   8.438  -8.383  -6.757  -0.973   \n",
       "T17  -4.649  ...   9.764  -2.794   4.974   1.406  -3.390   4.302   2.208   \n",
       "T18  -0.579  ...  -3.183  -4.020  -3.091  -9.126 -11.791   2.532  -1.150   \n",
       "T19  -1.905  ...  -2.098  -4.024  -1.812 -10.781  15.993  -1.514   0.240   \n",
       "T20   0.907  ...  14.473  -4.022   2.814  -1.032  17.903  -4.415  -2.936   \n",
       "\n",
       "       1737    1738    1739  \n",
       "T1   29.186  60.692  51.970  \n",
       "T2   -9.614 -25.865 -47.552  \n",
       "T3  -18.183  32.383  74.061  \n",
       "T4   -1.926  21.709  38.714  \n",
       "T5   -7.298  -3.606  -9.818  \n",
       "T6    0.723  12.865   1.262  \n",
       "T7   12.992  16.353  14.963  \n",
       "T8   -7.423  12.649 -16.091  \n",
       "T9   -4.812 -16.777 -20.378  \n",
       "T10 -11.090  18.002  17.049  \n",
       "T11  -5.765  -8.298   3.359  \n",
       "T12   4.507   1.787  -8.688  \n",
       "T13 -12.753  -6.422  11.239  \n",
       "T14  24.113  13.087  13.895  \n",
       "T15 -11.103   4.987   4.201  \n",
       "T16  10.221  -0.385  -4.314  \n",
       "T17   6.244  -2.361   5.723  \n",
       "T18   3.147   3.002   1.753  \n",
       "T19 -12.922   2.043   0.906  \n",
       "T20   5.720   6.197  -0.798  \n",
       "\n",
       "[20 rows x 1740 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_df = pd.DataFrame(np.round(document_topics, 3), columns=['T'+str(i) for i in range(1, TOTAL_TOPICS+1)])\n",
    "dt_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document#13:\n",
      "Dominant Topics (top 3):  ['T1', 'T5', 'T9']\n",
      "Paper Summary: \n",
      "534 \n",
      "The Performance of Convex Set Projection Based Neural Networks \n",
      "Robert J. Marks II, Les E. Atlas, Seho Oh and James A. Ritcey \n",
      "Interactive Systems Design Lab, FT-10 \n",
      "University of Washington, Seattle, Wa 98195. \n",
      "ABSTRACT \n",
      "We donsider a class of neural networks whose performance can be \n",
      "analyzed and geometrically visualized in a signal space \n",
      "environment. Alternating projection neural networks (APNN's) \n",
      "perform by alternately projecting between two or more constraint \n",
      "sets. Criteria for desi\n",
      "\n",
      "Document#250:\n",
      "Dominant Topics (top 3):  ['T1', 'T7', 'T13']\n",
      "Paper Summary: \n",
      "558 Rohwer \n",
      "The 'Moving Targets' Training Algorithm \n",
      "Richard Rohwer \n",
      "Centre for Speech Technology Research \n",
      "Edinburgh University \n",
      "80, South Bridge \n",
      "Edinburgh EH1 1HN SCOTLAND \n",
      "ABSTRACT \n",
      "A simple method for training the dynamical behavior of a neu- \n",
      "ral network is derived. It is applicable to any training problem \n",
      "in discrete-time networks with arbitrary feedback. The algorithm \n",
      "resembles back-propagation in that an error function is minimized \n",
      "using a gradient-based method, but the optimization \n",
      "\n",
      "Document#500:\n",
      "Dominant Topics (top 3):  ['T1', 'T3', 'T14']\n",
      "Paper Summary: \n",
      "Adaptive Elastic Models for Hand-Printed \n",
      "Character Recognition \n",
      "Geoffrey E. Hinton, Christopher K. I. Williams and Michael D. Revow \n",
      "Department of Computer Science, University of Toronto \n",
      "Toronto, Ontario, Canada MSS 1A4 \n",
      "Abstract \n",
      "Hand-printed digits can be modeled as splines that are governed by about \n",
      "8 control points. For each known digit, the control points have preferred \n",
      "\"home\" locations, and deformations of the digit are generated by moving \n",
      "the control points away from their home locat\n",
      "\n"
     ]
    }
   ],
   "source": [
    "document_numbers = [13, 250, 500]\n",
    "for document_number in document_numbers:\n",
    "    top_topics = list(dt_df.columns[np.argsort(-np.absolute(dt_df.iloc[document_number].values))[:3]])\n",
    "    print('Document#'+str(document_number)+':')\n",
    "    print('Dominant Topics (top 3): ', top_topics)\n",
    "    print('Paper Summary: ')\n",
    "    print(papers[document_number][:500])\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
